{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utils for Colab"
      ],
      "metadata": {
        "id": "_WtXp-dGPPjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "pYa3_9YKPSRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4a9c7f-4bee-4710-e1aa-cfe3fa2ca087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "VrgJx21kPZxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e193f1b-7849-464a-ff43-406035321e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAHhcIPcXdj1"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAqybNvLSXPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e1e077-8798-4760-9b10-2b33324039e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Importing Package\n"
          ]
        }
      ],
      "source": [
        "# Importing Library\n",
        "import pywt\n",
        "import time\n",
        "import imblearn\n",
        "import numpy as np\n",
        "import keras_tuner\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing module\n",
        "from scipy import stats\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Importing Sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Importing Tensorflow and Keras Module\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from keras.layers import  Activation, Conv1D, Conv2D, Dense,\\\n",
        "     MaxPooling1D, Flatten, BatchNormalization, GRU, Input, Dropout,\\\n",
        "     MaxPooling2D, concatenate\n",
        "\n",
        "print(\"Done Importing Package\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class PREPROCESSING"
      ],
      "metadata": {
        "id": "jvSqUDu6QrOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PREPROCESSING():\n",
        "  def __init__(self):\n",
        "    self.x_file     = []\n",
        "    self.y_file     = []\n",
        "    self.x_train    = None\n",
        "    self.x_test     = None\n",
        "    self.y_train    = None\n",
        "    self.y_test     = None\n",
        "    self.sum_data   = None\n",
        "    self.len_data   = None\n",
        "    self.depth_data = None\n",
        "\n",
        "  def collect_data(self, no_file, database):\n",
        "    self.x_file     = []\n",
        "    self.y_file     = []\n",
        "    for i in range(no_file):\n",
        "      data = pd.read_csv(f\"Sleep_Stage_Identification/Dataset{database}/Data_EEG_s{i}.txt\", delimiter=\";\", header=None).dropna()\n",
        "      # data = pd.read_csv(f\"/content/gdrive/MyDrive/Dataset/Dataset{database}/Data_EEG_s{i}.txt\", delimiter=\";\", header=None).dropna()\n",
        "      x_col = data.iloc[:, 1:3001].to_numpy()\n",
        "      y_col = data.iloc[:, 3001].to_numpy()\n",
        "      for j in range(len(data)):\n",
        "        self.x_file.append(x_col[j])\n",
        "        self.y_file.append(y_col[j])\n",
        "\n",
        "    self.x_file = np.array(self.x_file)\n",
        "    self.y_file = np.reshape(self.y_file, (-1, 1))\n",
        "    print(f\"Length of signal data : {self.x_file.shape}\")\n",
        "\n",
        "  def collect_data_train(self):\n",
        "    data = pd.read_csv(f\"Sleep_Stage_Identification/TrainDataset/TrainingDataset.txt\", delimiter=\";\", header=None).dropna()\n",
        "    x_col = data.iloc[:,:3000].to_numpy()\n",
        "    y_col = data.iloc[:, 3000].to_numpy()\n",
        "    self.x_file = np.array(x_col)\n",
        "    self.y_file = np.reshape(y_col, (-1, 1))\n",
        "    print(f\"Length of signal data : {self.x_file.shape}\")\n",
        "\n",
        "  def collect_data_test(self):\n",
        "    data = pd.read_csv(f\"Sleep_Stage_Identification/TestDataset/TestingDataset.txt\", delimiter=\";\", header=None).dropna()\n",
        "    x_col = data.iloc[:,:3000].to_numpy()\n",
        "    y_col = data.iloc[:, 3000].to_numpy()\n",
        "    self.x_file = np.array(x_col)\n",
        "    self.y_file = np.reshape(y_col, (-1, 1))\n",
        "    print(f\"Length of signal data : {self.x_file.shape}\")\n",
        "\n",
        "  def filter_signal(self, raw_freq, low, high):\n",
        "    self.x_file = mne.filter.filter_data(self.x_file, raw_freq, low, high)\n",
        "    print(self.x_file.shape)\n",
        "\n",
        "  def smote(self):\n",
        "    counter = Counter(self.y_file.flatten())\n",
        "    print(f\"Number of Each classes before SMOTE : {counter}\")\n",
        "    oversample = SMOTE()\n",
        "    self.x_file, self.y_file = oversample.fit_resample(self.x_file, self.y_file)\n",
        "    self.y_file= np.reshape(self.y_file, (-1, 1))\n",
        "    counter = Counter(self.y_file.flatten())\n",
        "    print(f\"Number of Each classes after SMOTE  : {counter}\")\n",
        "\n",
        "  def wavelet(self, fams):\n",
        "    wp = pywt.WaveletPacket2D(data=self.x_file, wavelet=fams, mode='zero')\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "    w_1 = wp['addd'].data\n",
        "    w_2 = wp['daaa'].data\n",
        "    w_3 = wp['daad'].data\n",
        "    w_4 = wp['dada'].data\n",
        "    w_5 = wp['dadd'].data\n",
        "    w_6 = wp['ddaa'].data\n",
        "    w = np.concatenate((w_1,w_2,w_3,w_4,w_5,w_6), axis=0)\n",
        "    w=scaler.fit_transform(w)\n",
        "\n",
        "    n1_1 = wp['aadd'].data\n",
        "    n1_2 = wp['adaa'].data\n",
        "    n1_3 = wp['adad'].data\n",
        "    n1_4 = wp['adda'].data\n",
        "    n1 = np.concatenate((n1_1,n1_2, n1_3,n1_4), axis=0)\n",
        "    n1=scaler.fit_transform(n1)\n",
        "\n",
        "    n2_1 = wp['dada'].data\n",
        "    n2_2 = wp['dadd'].data\n",
        "    n2_3 = wp['ddaa'].data\n",
        "    n2_4 = wp['ddad'].data\n",
        "    n2_5 = wp['ddda'].data\n",
        "    n2_6 = wp['dddd'].data\n",
        "    n2 = np.concatenate((n2_1,n2_2,n2_3,n2_4,n2_5,n2_6), axis=0)\n",
        "    n2=scaler.fit_transform(n2)\n",
        "\n",
        "    n3_1 = wp['aaaa'].data\n",
        "    n3_2 = wp['aaad'].data\n",
        "    n3 = np.concatenate((n3_1,n3_2), axis=0)\n",
        "    n3=scaler.fit_transform(n3)\n",
        "\n",
        "    r_1 = wp['aaad'].data\n",
        "    r_2 = wp['aada'].data\n",
        "    r_3 = wp['aadd'].data\n",
        "    r_4 = wp['adaa'].data\n",
        "    r_5 = wp['adad'].data\n",
        "    r = np.concatenate((r_1,r_2,r_3,r_4,r_5), axis=0)\n",
        "    r=scaler.fit_transform(r)\n",
        "\n",
        "    w_label = []\n",
        "    lab_w = [[1] * 1 for i in range(len(w))]\n",
        "    w_label = np.asarray(lab_w)\n",
        "\n",
        "    n1_label = []\n",
        "    lab_n1 = [[2] * 1 for i in range(len(n1))]\n",
        "    n1_label = np.asarray(lab_n1)\n",
        "\n",
        "    n2_label = []\n",
        "    lab_2 = [[3] * 1 for i in range(len(n2))]\n",
        "    n2_label = np.asarray(lab_2)\n",
        "\n",
        "    n3_label = []\n",
        "    lab_3 = [[4] * 1 for i in range(len(n3))]\n",
        "    n3_label = np.asarray(lab_3)\n",
        "\n",
        "    r_label = []\n",
        "    lab_r = [[5] * 1 for i in range(len(r))]\n",
        "    r_label = np.asarray(lab_r)\n",
        "\n",
        "    self.x_file = np.concatenate((w,n1, n2, n3, r), axis=0)\n",
        "    self.y_file = np.concatenate((w_label, n1_label, n2_label, n3_label, r_label), axis=0)\n",
        "\n",
        "    print(f\"X File shape after Wavelet: {self.x_file.shape}\")\n",
        "    print(f\"Y File shape after Wavelet: {self.y_file.shape}\")\n",
        "\n",
        "  def scaler_signal(self):\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    self.x_file=scaler.fit_transform(self.x_file)\n",
        "\n",
        "  def split_reshape(self, test_size):\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x_file, self.y_file, test_size=test_size, random_state=0)\n",
        "\n",
        "    self.x_train = self.x_train.reshape(self.x_train.shape[0], self.x_train.shape[1] , 1)\n",
        "    self.x_test  = self.x_test.reshape(self.x_test.shape[0], self.x_test.shape[1] , 1)\n",
        "\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    self.y_train = oneHot.fit_transform(self.y_train)\n",
        "    self.y_test = oneHot.fit_transform(self.y_test)\n",
        "\n",
        "    print(f\"X and Y Train Shape after reshaping : {self.x_train.shape}{self.y_train.shape}\")\n",
        "    print(f\"X and Y Test Shape after reshaping  : {self.x_test.shape}{self.y_test.shape}\")\n",
        "\n",
        "    self.sum_data   = self.x_train.shape[0]\n",
        "    self.len_data   = self.x_train.shape[1]\n",
        "    self.depth_data = self.x_train.shape[2]\n"
      ],
      "metadata": {
        "id": "r3xIIME0QrhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class PREPARE_DATA\n"
      ],
      "metadata": {
        "id": "82EXHh2B0l1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PREPARE_DATA():\n",
        "  def __init__(self):\n",
        "    self.x_train      = None\n",
        "    self.x_test       = None\n",
        "    self.y_train      = None\n",
        "    self.y_test       = None\n",
        "    self.height_data  = None\n",
        "    self.len_data     = None\n",
        "    self.depth_data   = None\n",
        "    self.TESTING_SIZE = 0.3\n",
        "    self.WAVELET      = 'db9' # Wavelet family\n",
        "    self.pre          = PREPROCESSING()\n",
        "\n",
        "  def prepro_wavelet_datatrain(self):\n",
        "    start_time = time.time()\n",
        "    print(f\"Start Pre-Proccessing :{datetime.now()}\")\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_train()  # Collect data train\n",
        "    self.pre.wavelet(self.WAVELET)  # Wavelet\n",
        "    self.pre.smote() # Smote\n",
        "    self.pre.split_reshape(self.TESTING_SIZE)\n",
        "    self.x_train, sDelf.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(f\"Finish Pre-Proccessing :{datetime.now()}\")\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_wavelet_datatest(self):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_test()  # Collect data train\n",
        "    self.pre.wavelet(self.WAVELET)  # Wavelet\n",
        "    self.pre.smote() # Smote\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    self.y_test = oneHot.fit_transform(self.pre.y_file)\n",
        "    self.x_test = self.pre.x_file\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_datatrain(self):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_train()  # Collect data train\n",
        "    self.pre.scaler_signal()  # Minmax Scaler\n",
        "    self.pre.split_reshape(self.TESTING_SIZE)\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_datatest(self):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_test()  # Collect data train\n",
        "    self.pre.scaler_signal()\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    self.y_test = oneHot.fit_transform(self.pre.y_file)\n",
        "    self.x_test = self.pre.x_file\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_wavelet_datafile(self, NUMBER_OF_FILE, NO_DATABASE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    ## Pre-processing\n",
        "    self.pre.collect_data(NUMBER_OF_FILE,NO_DATABASE)  ## Collect data file\n",
        "    self.pre.wavelet(self.WAVELET)  ## Wavelet\n",
        "    self.pre.smote() # Smote\n",
        "    self.pre.split_reshape(self.TESTING_SIZE)\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_datafile(self, NUMBER_OF_FILE, NO_DATABASE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE,NO_DATABASE)  ## Collect data file\n",
        "    self.pre.smote() # Smote\n",
        "    self.pre.scaler_signal()  ## Minmax Scaler\n",
        "    self.pre.split_reshape(self.TESTING_SIZE)\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "\n",
        "  def prepro_wavelet_datafile_2D(self, NUMBER_OF_FILE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE, 3)\n",
        "    self.pre.wavelet('coif16')\n",
        "    self.pre.smote()\n",
        "    x1_file = self.pre.x_file\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    y_file = oneHot.fit_transform(self.pre.y_file)\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE, 4)\n",
        "    self.pre.wavelet('coif16')\n",
        "    self.pre.smote()\n",
        "    x2_file = self.pre.x_file\n",
        "\n",
        "    x_file = np.zeros(276)\n",
        "    for i in range(len(x1_file)):\n",
        "      x_file = np.vstack((x_file, x1_file[i]))\n",
        "      x_file = np.vstack((x_file, x2_file[i]))\n",
        "\n",
        "    x_file = np.delete(x_file, 0, axis=0)\n",
        "    x_file = np.reshape(x_file,(-1, 24, 23, 1))\n",
        "    print(f\"Size of X and Y File : {x_file.shape} {y_file.shape}\")\n",
        "\n",
        "    mat = int(np.floor(len(x_file)*(1 - self.TESTING_SIZE)))\n",
        "    print(f\"Mat : {mat}\")\n",
        "\n",
        "    self.x_train =  x_file[0:mat]\n",
        "    self.y_train = y_file[0:mat]\n",
        "    self.x_test  = x_file[mat:]\n",
        "    self.y_test  = y_file[mat:]\n",
        "\n",
        "    self.height_data = self.x_train.shape[1]\n",
        "    self.len_data    = self.x_train.shape[2]\n",
        "    self.depth_data  = self.x_train.shape[3]\n",
        "\n",
        "    print(f\"X and Y Train Shape after reshaping : {self.x_train.shape} {self.y_train.shape}\")\n",
        "    print(f\"X and Y Test Shape after reshaping  :  {self.x_test.shape} {self.y_test.shape}\")\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "\n",
        "  def prepro_datafile_2D(self, NUMBER_OF_FILE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE, 3)\n",
        "    self.pre.smote()\n",
        "    x1_file = self.pre.x_file\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    y_file = oneHot.fit_transform(self.pre.y_file)\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE, 4)\n",
        "    self.pre.smote()\n",
        "    x2_file = self.pre.x_file\n",
        "\n",
        "    x_file = np.zeros(3000)\n",
        "    for i in range(len(x1_file)):\n",
        "      x_file = np.vstack((x_file, x1_file[i]))\n",
        "      x_file = np.vstack((x_file, x2_file[i]))\n",
        "\n",
        "    x_file = np.delete(x_file, 0, axis=0)\n",
        "    x_file = np.reshape(x_file,(-1, 60, 100, 1))\n",
        "    print(f\"Size of X and Y File : {x_file.shape} {y_file.shape}\")\n",
        "\n",
        "    mat = int(np.floor(len(x_file)*(1 - self.TESTING_SIZE)))\n",
        "    print(f\"Mat : {mat}\")\n",
        "\n",
        "    self.x_train =  x_file[0:mat]\n",
        "    self.y_train = y_file[0:mat]\n",
        "    self.x_test  = x_file[mat:]\n",
        "    self.y_test  = y_file[mat:]\n",
        "\n",
        "    self.height_data = self.x_train.shape[1]\n",
        "    self.len_data    = self.x_train.shape[2]\n",
        "    self.depth_data  = self.x_train.shape[3]\n",
        "\n",
        "    print(f\"X and Y Train Shape after reshaping : {self.x_train.shape} {self.y_train.shape}\")\n",
        "    print(f\"X and Y Test Shape after reshaping  :  {self.x_test.shape} {self.y_test.shape}\")\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "id": "ApBZuy140wRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class MODEL"
      ],
      "metadata": {
        "id": "Ae4mrPzC8tz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MODEL():\n",
        "  def __init__(self):\n",
        "    self.FILTER_1      = 64 \n",
        "    self.FILTER_2      = 192 \n",
        "    self.FILTER_3      = 384\n",
        "\n",
        "    self.KERNEL_SIZE   = 3\n",
        "    self.POOL_SIZE     = 2\n",
        "    self.GRU_COUNT     = 512\n",
        "\n",
        "    self.DENSE_1       = 1024\n",
        "    self.DENSE_2       = 256\n",
        "    self.DENSE_3       = 64\n",
        "\n",
        "    self.STRIDES       = 1\n",
        "    self.DROPOUT       = 0.5\n",
        "    self.NUM_CLASSES   = 5\n",
        "    self.LEARNING_RATE = 0.001\n",
        "\n",
        "    self.OPTIMIZER     = tf.optimizers.Adam(learning_rate = self.LEARNING_RATE)\n",
        "    # self.OPTIMIZER     = tf.optimizers.SGD(learning_rate = self.LEARNING_RATE)\n",
        "    self.LOSS          = 'binary_crossentropy'\n",
        "\n",
        "  def CNN1D_RNN(self, model_input):\n",
        "    print('\\nBuilding 1D CNN-RNN Model \\n')\n",
        "    \n",
        "    ## Convolutional Blocks\n",
        "    conv_1  = Conv1D(filters = self.FILTER_1, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_1')(model_input)                  \n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    pool_1  = MaxPooling1D(self.POOL_SIZE)(batch_1)\n",
        "    drop_1  = Dropout(self.DROPOUT)(pool_1)\n",
        "\n",
        "    conv_2  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_2')(drop_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "    pool_2  = MaxPooling1D(self.POOL_SIZE)(batch_2)\n",
        "\n",
        "    conv_3  = Conv1D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_3')(pool_2)\n",
        "    batch_3 = BatchNormalization()(conv_3)\n",
        "    pool_3  = MaxPooling1D(self.POOL_SIZE)(batch_3)\n",
        "    drop_3  = Dropout(self.DROPOUT)(pool_3)\n",
        "\n",
        "    conv_4  = Conv1D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_4')(pool_3)\n",
        "    batch_4 = BatchNormalization()(conv_4)\n",
        "    pool_4  = MaxPooling1D(self.POOL_SIZE)(batch_4)\n",
        "\n",
        "    conv_5  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_5')(pool_4)\n",
        "    batch_5 = BatchNormalization()(conv_5)\n",
        "    pool_5  = MaxPooling1D(self.POOL_SIZE)(batch_5)\n",
        "    drop_5  = Dropout(self.DROPOUT)(pool_5)\n",
        "\n",
        "    # conv_6  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_6')(pool_5)\n",
        "    # batch_6 = BatchNormalization()(conv_6)\n",
        "    # pool_6  = MaxPooling1D(self.POOL_SIZE)(batch_6)\n",
        "    # drop_6  = Dropout(self.DROPOUT)(pool_6)\n",
        "\n",
        "    flatten = Flatten()(drop_5)\n",
        "    dense_1 = Dense(self.DENSE_1, activation='relu' )(flatten)\n",
        "    dense_2 = Dense(self.DENSE_2, activation='relu' )(dense_1)\n",
        "    dense_3 = Dense(self.DENSE_3, activation='relu' )(dense_2)\n",
        "\n",
        "    ## Recurrent Block\n",
        "    pool_gru = MaxPooling1D(self.POOL_SIZE, name = 'pool_gru')(model_input)\n",
        "    gru      = GRU(self.GRU_COUNT,activation='tanh', recurrent_activation='sigmoid', recurrent_dropout=0.0, unroll=False, use_bias=True, reset_after=True)(pool_gru) \n",
        "    gflatten = Flatten()(gru)\n",
        "    \n",
        "    ## Concat Output\n",
        "    concat = concatenate([dense_3, gflatten], axis=-1, name ='concat')\n",
        "    \n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(concat)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def GRU_1D(self, model_input):\n",
        "    print('\\nBuilding GRU Model \\n')\n",
        "\n",
        "    ### Recurrent Block\n",
        "    # pool_gru = MaxPooling1D(self.POOL_SIZE, name = 'pool_gru')(model_input)\n",
        "    gru_1   = GRU(self.GRU_COUNT,activation='tanh', recurrent_activation='sigmoid', recurrent_dropout=0.0, unroll=False, use_bias=True, reset_after=True)(model_input) \n",
        "    drop_1  = Dropout(self.DROPOUT)(gru_1)\n",
        "    batch_1 = BatchNormalization()(drop_1)\n",
        "    flatten = Flatten()(batch_1)\n",
        "\n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(flatten)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        " \n",
        "    return model\n",
        "\n",
        "  def CNN_1D(self, model_input):\n",
        "    print('\\nBuilding 1D CNN Model \\n')\n",
        "    \n",
        "    ### Convolutional Blocks 1\n",
        "    conv_1  = Conv1D(filters = self.FILTER_1, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_1')(model_input)                  \n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    pool_1  = MaxPooling1D(self.POOL_SIZE)(batch_1)\n",
        "    drop_1  = Dropout(self.DROPOUT)(pool_1)\n",
        "\n",
        "    conv_2  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_2')(drop_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "    pool_2  = MaxPooling1D(self.POOL_SIZE)(batch_2)\n",
        "\n",
        "    conv_3  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_3')(pool_2)\n",
        "    batch_3 = BatchNormalization()(conv_3)\n",
        "    pool_3  = MaxPooling1D(self.POOL_SIZE)(batch_3)\n",
        "\n",
        "    conv_4  = Conv1D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_4')(pool_3)\n",
        "    batch_4 = BatchNormalization()(conv_4)\n",
        "    pool_4  = MaxPooling1D(self.POOL_SIZE)(batch_4)\n",
        "\n",
        "    conv_5  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_5')(pool_4)\n",
        "    batch_5 = BatchNormalization()(conv_5)\n",
        "    pool_5  = MaxPooling1D(self.POOL_SIZE)(batch_5)\n",
        "    drop_5  = Dropout(self.DROPOUT)(pool_5)\n",
        "\n",
        "    # conv_6  = Conv1D(filters = self.FILTER_1, kernel_size = KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_6')(pool_5)\n",
        "    # batch_6 = BatchNormalization()(conv_6)\n",
        "    # pool_6  = MaxPooling1D(self.POOL_SIZE)(batch_6)\n",
        "    # drop_6  = Dropout(self.DROPOUT)(pool_6)\n",
        "\n",
        "    flatten = Flatten()(drop_5)\n",
        "    dense_1 = Dense(self.DENSE_1, activation='relu' )(flatten)\n",
        "    dense_2 = Dense(self.DENSE_2, activation='relu' )(dense_1)\n",
        "    dense_3 = Dense(self.DENSE_3, activation='relu' )(dense_2)\n",
        "\n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(dense_3)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        "        \n",
        "    return model\n",
        "\n",
        "  def CNN1D_RNN_seq(self, model_input):\n",
        "    print('\\nBuilding 1D CNN-RNN Model \\n')\n",
        "    \n",
        "    ## Convolutional Blocks\n",
        "    conv_1  = Conv1D(filters = self.FILTER_1, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_1')(model_input)                  \n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    pool_1  = MaxPooling1D(self.POOL_SIZE)(batch_1)\n",
        "    drop_1  = Dropout(self.DROPOUT)(pool_1)\n",
        "\n",
        "    conv_2  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_2')(drop_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "    pool_2  = MaxPooling1D(self.POOL_SIZE)(batch_2)\n",
        "\n",
        "    conv_3  = Conv1D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_3')(pool_2)\n",
        "    batch_3 = BatchNormalization()(conv_3)\n",
        "    pool_3  = MaxPooling1D(self.POOL_SIZE)(batch_3)\n",
        "    drop_3  = Dropout(self.DROPOUT)(pool_3)\n",
        "\n",
        "    # conv_4  = Conv1D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_4')(pool_3)\n",
        "    # batch_4 = BatchNormalization()(conv_4)\n",
        "    # pool_4  = MaxPooling1D(self.POOL_SIZE)(batch_4)\n",
        "\n",
        "    # conv_5  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_5')(pool_4)\n",
        "    # batch_5 = BatchNormalization()(conv_5)\n",
        "    # pool_5  = MaxPooling1D(self.POOL_SIZE)(batch_5)\n",
        "    # drop_5  = Dropout(self.DROPOUT)(pool_5)\n",
        "\n",
        "    # conv_6  = Conv1D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_6')(pool_5)\n",
        "    # batch_6 = BatchNormalization()(conv_6)\n",
        "    # pool_6  = MaxPooling1D(self.POOL_SIZE)(batch_6)\n",
        "    # drop_6  = Dropout(self.DROPOUT)(pool_6)\n",
        "\n",
        "    # flatten = Flatten()(drop_5)\n",
        "    # dense_1 = Dense(self.DENSE_1, activation='relu' )(flatten)\n",
        "    # dense_2 = Dense(self.DENSE_2, activation='relu' )(dense_1)\n",
        "    # dense_3 = Dense(self.DENSE_3, activation='relu' )(dense_2)\n",
        "\n",
        "    ## Recurrent Block\n",
        "    # pool_gru = MaxPooling1D(self.POOL_SIZE, name = 'pool_gru')(model_input)\n",
        "    gru      = GRU(self.GRU_COUNT,activation='tanh', recurrent_activation='sigmoid', recurrent_dropout=0.0, unroll=False, use_bias=True, reset_after=True)(drop_3) \n",
        "    gflatten = Flatten()(gru)\n",
        "    \n",
        "    ## Concat Output\n",
        "    # concat = concatenate([dense_3, gflatten], axis=-1, name ='concat')\n",
        "    \n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(gflatten)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNN_2D(self, model_input):\n",
        "    print('\\nBuilding 1D CNN Model \\n')\n",
        "    \n",
        "    ### Convolutional Blocks 1\n",
        "    conv_1  = Conv2D(filters = self.FILTER_1, kernel_size = (1,2), strides = (1,1), padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_1')(model_input)                  \n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    pool_1  = MaxPooling2D(pool_size =(2, 2))(batch_1)\n",
        "    drop_1  = Dropout(self.DROPOUT)(pool_1)\n",
        "\n",
        "    conv_2  = Conv2D(filters = self.FILTER_1, kernel_size = (1,2), strides = (1,1), padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_2')(drop_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "    pool_2  = MaxPooling2D(pool_size =(2, 2))(batch_2)\n",
        "\n",
        "    # conv_3  = Conv2D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_3')(pool_2)\n",
        "    # batch_3 = BatchNormalization()(conv_3)\n",
        "    # pool_3  = MaxPooling1D(self.POOL_SIZE)(batch_3)\n",
        "\n",
        "    # conv_4  = Conv2D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_4')(pool_3)\n",
        "    # batch_4 = BatchNormalization()(conv_4)\n",
        "    # pool_4  = MaxPooling1D(self.POOL_SIZE)(batch_4)\n",
        "\n",
        "    # conv_5  = Conv2D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_5')(pool_4)\n",
        "    # batch_5 = BatchNormalization()(conv_5)\n",
        "    # pool_5  = MaxPooling1D(self.POOL_SIZE)(batch_5)\n",
        "    # drop_5  = Dropout(self.DROPOUT)(pool_5)\n",
        "\n",
        "\n",
        "    flatten = Flatten()(pool_2)\n",
        "    dense_1 = Dense(self.DENSE_1, activation='relu' )(flatten)\n",
        "    dense_2 = Dense(self.DENSE_2, activation='relu' )(dense_1)\n",
        "    dense_3 = Dense(self.DENSE_3, activation='relu' )(dense_2)\n",
        "\n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(dense_3)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def training_model(self, x_train, y_train,x_test, y_test, len_data, depth_data, BATCH_SIZE, EPOCH_COUNT, FILE_NAME):\n",
        "    Model = MODEL()\n",
        "    ## Create model input\n",
        "    input_shape = (len_data, depth_data)\n",
        "    model_input = Input(input_shape, name='input')\n",
        "\n",
        "    input_shape_2d = (24, len_data, depth_data)\n",
        "    model_input_2d = Input(input_shape_2d, name='input_2d')\n",
        "\n",
        "    ## Callbacks\n",
        "    checkpoint_callback = ModelCheckpoint(f\"./models/{FILE_NAME}.h5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='max')\n",
        "    reducelr_callback = ReduceLROnPlateau(monitor='val_accuracy', factor=0, patience=100, min_delta=0.01,verbose=1)\n",
        "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
        "\n",
        "    ## Model \n",
        "    model = Model.CNN1D_RNN(model_input) # Model 1D CNN - RNN\n",
        "    # model = Model.CNN_1D(model_input) # Model CNN 5 Layer\n",
        "    # model = Model.GRU_1D(model_input) # Model GRU\n",
        "    # model = Model.CNN1D_RNN_seq(model_input) # Model 1D CNN - RNN Sequence\n",
        "    # model = Model.CNN_2D(model_input_2d) # Model CNN 5 Layer\n",
        "\n",
        "    model.summary()\n",
        "    start_time = time.time()\n",
        "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks_list)\n",
        "    \n",
        "    # Calculate loss and accuracy\n",
        "    print(\"\\nCalculate loss and accuracy of the model\\n\")\n",
        "    score_train = model.evaluate(x_train,y_train)\n",
        "    print(\"Train Loss     : \",score_train[0])\n",
        "    print(\"Train Accuracy : \",score_train[1]*100)\n",
        "    score_test = model.evaluate(x_test,y_test)\n",
        "    print(\"Test Loss      : \",score_test[0])\n",
        "    print(\"Test Accuracy  : \",score_test[1]*100)  \n",
        "\n",
        "    print(f\"Duration of execution : {time.time() - start_time} seconds\")\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Loss', 'Validation Loss'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "sH1Jp5Th8wTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Model 2D"
      ],
      "metadata": {
        "id": "8gSpgp6I9hVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MODEL_2D():\n",
        "  def __init__(self):\n",
        "    self.FILTER_1      = 64 \n",
        "    self.FILTER_2      = 192 \n",
        "    self.FILTER_3      = 384\n",
        "\n",
        "    self.KERNEL_SIZE   = (2,2)\n",
        "    self.POOL_SIZE     = (2,2)\n",
        "    self.GRU_COUNT     = 512\n",
        "\n",
        "    self.DENSE_1       = 1024\n",
        "    self.DENSE_2       = 256\n",
        "    self.DENSE_3       = 64\n",
        "\n",
        "    self.STRIDES       = (1,1)\n",
        "    self.DROPOUT       = 0.5\n",
        "    self.NUM_CLASSES   = 5\n",
        "    self.LEARNING_RATE = 0.001\n",
        "\n",
        "    self.OPTIMIZER     = tf.optimizers.Adam(learning_rate = self.LEARNING_RATE)\n",
        "    # self.OPTIMIZER     = tf.optimizers.SGD(learning_rate = self.LEARNING_RATE)\n",
        "    self.LOSS          = 'binary_crossentropy'\n",
        "\n",
        "  def CNN_2D(self, model_input):\n",
        "    print('\\nBuilding 1D CNN Model \\n')\n",
        "    \n",
        "    ### Convolutional Blocks 1\n",
        "    conv_1  = Conv2D(filters = self.FILTER_1, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_1')(model_input)                  \n",
        "    batch_1 = BatchNormalization()(conv_1)\n",
        "    pool_1  = MaxPooling2D(pool_size =self.POOL_SIZE)(batch_1)\n",
        "    drop_1  = Dropout(self.DROPOUT)(pool_1)\n",
        "\n",
        "    conv_2  = Conv2D(filters = self.FILTER_1, kernel_size = (1,2), strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_2')(drop_1)\n",
        "    batch_2 = BatchNormalization()(conv_2)\n",
        "    pool_2  = MaxPooling2D(pool_size =self.POOL_SIZE)(batch_2)\n",
        "\n",
        "    # conv_3  = Conv2D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_3')(pool_2)\n",
        "    # batch_3 = BatchNormalization()(conv_3)\n",
        "    # pool_3  = MaxPooling1D(self.POOL_SIZE)(batch_3)\n",
        "\n",
        "    # conv_4  = Conv2D(filters = self.FILTER_3, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_4')(pool_3)\n",
        "    # batch_4 = BatchNormalization()(conv_4)\n",
        "    # pool_4  = MaxPooling1D(self.POOL_SIZE)(batch_4)\n",
        "\n",
        "    # conv_5  = Conv2D(filters = self.FILTER_2, kernel_size = self.KERNEL_SIZE, strides = self.STRIDES, padding= 'valid', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), name='conv_5')(pool_4)\n",
        "    # batch_5 = BatchNormalization()(conv_5)\n",
        "    # pool_5  = MaxPooling1D(self.POOL_SIZE)(batch_5)\n",
        "    # drop_5  = Dropout(self.DROPOUT)(pool_5)\n",
        "\n",
        "    flatten = Flatten()(pool_2)\n",
        "    dense_1 = Dense(self.DENSE_1, activation='relu' )(flatten)\n",
        "    dense_2 = Dense(self.DENSE_2, activation='relu' )(dense_1)\n",
        "    dense_3 = Dense(self.DENSE_3, activation='relu' )(dense_2)\n",
        "\n",
        "    ## Softmax Output\n",
        "    model_output = Dense(self.NUM_CLASSES, activation = 'softmax', name='preds')(dense_3)\n",
        "    model        = Model(model_input, model_output)\n",
        "    model.compile(optimizer = self.OPTIMIZER,loss = self.LOSS, metrics =['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def training_model(self, x_train, y_train,x_test, y_test, height_data, len_data, depth_data, BATCH_SIZE, EPOCH_COUNT, FILE_NAME):\n",
        "    Model = MODEL()\n",
        "    ## Create model input\n",
        "\n",
        "    input_shape_2d = (height_data , len_data, depth_data)\n",
        "    model_input_2d = Input(input_shape_2d, name='input_2d')\n",
        "\n",
        "    ## Callbacks\n",
        "    checkpoint_callback = ModelCheckpoint(f\"./models/{FILE_NAME}.h5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='max')\n",
        "    reducelr_callback = ReduceLROnPlateau(monitor='val_accuracy', factor=0, patience=100, min_delta=0.01,verbose=1)\n",
        "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
        "\n",
        "    ## Model \n",
        "    model = Model.CNN_2D(model_input_2d) # Model CNN 5 Layer\n",
        "\n",
        "    model.summary()\n",
        "    start_time = time.time()\n",
        "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks_list)\n",
        "    \n",
        "    # Calculate loss and accuracy\n",
        "    print(\"\\nCalculate loss and accuracy of the model\\n\")\n",
        "    score_train = model.evaluate(x_train,y_train)\n",
        "    print(\"Train Loss     : \",score_train[0])\n",
        "    print(\"Train Accuracy : \",score_train[1]*100)\n",
        "    score_test = model.evaluate(x_test,y_test)\n",
        "    print(\"Test Loss      : \",score_test[0])\n",
        "    print(\"Test Accuracy  : \",score_test[1]*100)  \n",
        "\n",
        "    print(f\"Duration of execution : {time.time() - start_time} seconds\")\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Loss', 'Validation Loss'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return history, model"
      ],
      "metadata": {
        "id": "R-V6K58p9guE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class IDENTIFICATION"
      ],
      "metadata": {
        "id": "s5HlHgGSTZlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IDENTIFICATION():\n",
        "  def __init__(self):\n",
        "    self.model         = None\n",
        "    self.x_train       = None\n",
        "    self.x_test        = None\n",
        "    self.y_train       = None\n",
        "    self.y_test        = None\n",
        "    self.len_data      = None\n",
        "    self.depth_data    = None\n",
        "    self.TRAINING_SIZE = 0.9\n",
        "    self.WAVELET       = 'db9' # Wavelet family\n",
        "    self.pre           = PREPROCESSING()\n",
        "\n",
        "  def prepro_wavelet_datatest(self):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_test()  # Collect data train\n",
        "    self.pre.wavelet(self.WAVELET)  # Wavelet\n",
        "    self.pre.smote() # Smote\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    self.y_test = oneHot.fit_transform(self.pre.y_file)\n",
        "    self.x_test = self.pre.x_file\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "\n",
        "  def prepro_datatest(self):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    # Pre-processing\n",
        "    self.pre.collect_data_test()  # Collect data train\n",
        "    self.pre.scaler_signal()\n",
        "    oneHot = OneHotEncoder(sparse=False)\n",
        "    self.y_test = oneHot.fit_transform(self.pre.y_file)\n",
        "    self.x_test = self.pre.x_file\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "\n",
        "  def prepro_wavelet_datafile(self, NUMBER_OF_FILE, NO_DATABASE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    ## Pre-processing\n",
        "    self.pre.collect_data(NUMBER_OF_FILE,NO_DATABASE)  ## Collect data file\n",
        "    self.pre.wavelet(self.WAVELET)  ## Wavelet\n",
        "    self.pre.smote() # Smote\n",
        "    self.pre.split_reshape(self.TRAINING_SIZE)\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "  \n",
        "  def prepro_datafile(self, NUMBER_OF_FILE, NO_DATABASE):\n",
        "    start_time = time.time()\n",
        "    print(\"Start Pre-Proccessing:\", datetime.now())\n",
        "\n",
        "    self.pre.collect_data(NUMBER_OF_FILE,NO_DATABASE)  ## Collect data file\n",
        "    self.pre.smote() # Smote\n",
        "    self.pre.scaler_signal()  ## Minmax Scaler\n",
        "    self.pre.split_reshape(self.TRAINING_SIZE)\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test, self.len_data, self.depth_data = self.pre.x_train, self.pre.x_test, self.pre.y_train, self.pre.y_test, self.pre.len_data, self.pre.depth_data\n",
        "\n",
        "    print(\"Finish Pre-Proccessing:\", datetime.now())\n",
        "    print(f\"Duration of execution  :{time.time() - start_time} seconds\")\n",
        "\n",
        "  def load_model(self, FILE_NAME):\n",
        "    weights_path = f\"./models/{FILE_NAME}.h5\"\n",
        "    self.model  = load_model(weights_path)\n",
        "\n",
        "  def identifikasi(self, x_test, y_test):\n",
        "    y_pred     = self.model.predict(x_test) \n",
        "    y_pred_max = np.argmax(y_pred, axis=1)\n",
        "    y_test_max = np.argmax(y_test, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(30,9))\n",
        "\n",
        "    plt.plot(y_pred_max[:130], drawstyle='steps', label='Prediction')\n",
        "    plt.ylabel('Sleep Stage')\n",
        "    plt.xlabel('Segmen')\n",
        "    plt.legend(['Prediction'], loc='upper left')\n",
        "    plt.title('Sleep Stage Prediction')\n",
        "    plt.show()\n",
        "\n",
        "  def self_identifikasi(self):\n",
        "    y_pred     = self.model.predict(self.x_test) \n",
        "    y_pred_max = np.argmax(y_pred, axis=1)\n",
        "    y_test_max = np.argmax(self.y_test, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(30,9))\n",
        "\n",
        "    plt.plot(y_pred_max[:130], drawstyle='steps', label='Prediction')\n",
        "    # plt.plot(y_test_max[:130], drawstyle='steps', label='Actual')\n",
        "    plt.ylabel('Sleep Stage')\n",
        "    plt.xlabel('Segmen')\n",
        "    plt.legend(['Prediction'], loc='upper left')\n",
        "    plt.title('Sleep Stage Prediction')\n",
        "    plt.show()\n",
        "\n",
        "  def cm_analysis(self, x_test, y_test):\n",
        "    dict_genres = {'W','N1', 'N2', 'N3', 'REM'}\n",
        "\n",
        "    y_pred      = self.model.predict(x_test) \n",
        "    y_pred_max  = np.argmax(y_pred, axis=1)\n",
        "    y_test_max  = np.argmax(y_test, axis=1)\n",
        "\n",
        "    cm           = confusion_matrix(y_test_max, y_pred_max)\n",
        "    cm_sum       = np.sum(cm, axis=1)\n",
        "    cm_perc      = cm / cm_sum.astype(float) * 100\n",
        "    annot        = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "      for j in range(ncols):\n",
        "        c = cm[i, j]\n",
        "        p = cm_perc[i, j]\n",
        "        if i == j:\n",
        "          s = cm_sum[i]\n",
        "          annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "        elif c == 0:\n",
        "          annot[i, j] = ''\n",
        "        else:\n",
        "          annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "\n",
        "    figsize = (9,9)\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cmap='Blues')\n",
        "    ax.set_title('Confusion Matrix of Identification Sleep Stage\\n\\n');\n",
        "    ax.set_xlabel('Predicted Values')\n",
        "    ax.set_ylabel('Actual Values ');\n",
        "    ax.xaxis.set_ticklabels(['W','N1', 'N2', 'N3', 'REM'])\n",
        "    ax.yaxis.set_ticklabels(['W','N1', 'N2', 'N3', 'REM'])\n",
        "\n",
        "    print(classification_report(y_test_max, y_pred_max, target_names=dict_genres))"
      ],
      "metadata": {
        "id": "Bfg7E08cTem5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Main"
      ],
      "metadata": {
        "id": "Qs0vEaUBHOqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAIN():\n",
        "  def __init__(self):\n",
        "    self.FILE_NAME      = \"test\"\n",
        "    self.NUMBER_OF_FILE = 3 # Number file that will be used to training model\n",
        "    self.NO_DATABASE    = 3 # Number of database\n",
        "    self.prepare        = PREPARE_DATA()\n",
        "    self.model          = MODEL()\n",
        "    self.model_2d       = MODEL_2D()\n",
        "    self.identification = IDENTIFICATION()\n",
        "\n",
        "  def train(self):\n",
        "    BATCH_SIZE     = 64\n",
        "    EPOCH_COUNT    = 5\n",
        "\n",
        "    ## Collect Data 1D\n",
        "    # self.prepare.prepro_wavelet_datatrain()\n",
        "    # self.prepare.prepro_datatrain()\n",
        "    # self.prepare.prepro_wavelet_datafile(self.NUMBER_OF_FILE, self.NO_DATABASE)\n",
        "    # self.prepare.prepro_datafile(self.NUMBER_OF_FILE, self.NO_DATABASE)\n",
        "\n",
        "    ## Collect Data 2D\n",
        "    # self.prepare.prepro_wavelet_datafile_2D(self.NUMBER_OF_FILE)\n",
        "    self.prepare.prepro_datafile_2D(self.NUMBER_OF_FILE)\n",
        "\n",
        "    ## Training Model 1D\n",
        "    # history, self.model = self.model.training_model(self.prepare.x_train, self.prepare.y_train, self.prepare.x_test, self.prepare.y_test, self.prepare.len_data, self.prepare.depth_data, BATCH_SIZE, EPOCH_COUNT, self.FILE_NAME)\n",
        "    \n",
        "    ## Training Model 2D\n",
        "    history, self.model = self.model_2d.training_model(self.prepare.x_train, self.prepare.y_train, self.prepare.x_test, self.prepare.y_test, self.prepare.height_data, self.prepare.len_data, self.prepare.depth_data, BATCH_SIZE, EPOCH_COUNT, self.FILE_NAME)\n",
        "    \n",
        "\n",
        "    ## Identification\n",
        "    # self.identification.load_model(self.FILE_NAME)\n",
        "    # self.identification.cm_analysis(self.prepare.x_test, self.prepare.y_test)\n",
        "    # self.identification.identifikasi(self.prepare.x_test, self.prepare.y_test)\n",
        "\n",
        "  def test(self):\n",
        "    # self.identification.prepro_wavelet_datatest()\n",
        "    # self.identification.prepro_datatest()\n",
        "    self.identification.prepro_wavelet_datafile(self.NUMBER_OF_FILE, self.NO_DATABASE)\n",
        "    # self.identification.prepro_datafile(self.NUMBER_OF_FILE, self.NO_DATABASE)\n",
        "\n",
        "    self.identification.load_model(self.FILE_NAME)\n",
        "    self.identification.self_identifikasi()\n",
        "\n",
        "main = MAIN()"
      ],
      "metadata": {
        "id": "RM2yhCWfaFRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main.train()\n",
        "# main.test()"
      ],
      "metadata": {
        "id": "CL_a733lakNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92071bca-15f4-45a7-9d6f-80613d575d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Pre-Proccessing: 2022-07-12 13:39:29.683195\n",
            "Length of signal data : (3049, 3000)\n",
            "Number of Each classes before SMOTE : Counter({3: 1527, 5: 478, 4: 464, 1: 373, 2: 207})\n",
            "Number of Each classes after SMOTE  : Counter({1: 1527, 2: 1527, 3: 1527, 4: 1527, 5: 1527})\n",
            "Length of signal data : (3049, 3000)\n",
            "Number of Each classes before SMOTE : Counter({3: 1527, 5: 478, 4: 464, 1: 373, 2: 207})\n",
            "Number of Each classes after SMOTE  : Counter({1: 1527, 2: 1527, 3: 1527, 4: 1527, 5: 1527})\n",
            "Size of X and Y File : (7635, 60, 100, 1) (7635, 5)\n",
            "Mat : 5344\n",
            "X and Y Train Shape after reshaping : (5344, 60, 100, 1) (5344, 5)\n",
            "X and Y Test Shape after reshaping  :  (2291, 60, 100, 1) (2291, 5)\n",
            "Finish Pre-Proccessing: 2022-07-12 13:47:36.017291\n",
            "Duration of execution  :486.3340961933136 seconds\n",
            "\n",
            "Building 1D CNN Model \n",
            "\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2d (InputLayer)       [(None, 60, 100, 1)]      0         \n",
            "                                                                 \n",
            " conv_1 (Conv2D)             (None, 60, 99, 64)        192       \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 60, 99, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 49, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 30, 49, 64)        0         \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 30, 48, 64)        8256      \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 30, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 24, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 23040)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              23593984  \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " preds (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,882,117\n",
            "Trainable params: 23,881,861\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "84/84 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.2861\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to ./models\\test.h5\n",
            "84/84 [==============================] - 5s 53ms/step - loss: 0.8295 - accuracy: 0.2861 - val_loss: 0.7500 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/5\n",
            "83/84 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.2895\n",
            "Epoch 2: val_accuracy did not improve from 0.00000\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.5257 - accuracy: 0.2897 - val_loss: 0.6434 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/5\n",
            "83/84 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.2809\n",
            "Epoch 3: val_accuracy did not improve from 0.00000\n",
            "84/84 [==============================] - 3s 41ms/step - loss: 0.4795 - accuracy: 0.2801 - val_loss: 0.6227 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/5\n",
            "83/84 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.2788\n",
            "Epoch 4: val_accuracy did not improve from 0.00000\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4739 - accuracy: 0.2790 - val_loss: 0.6172 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/5\n",
            "83/84 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.2871\n",
            "Epoch 5: val_accuracy did not improve from 0.00000\n",
            "84/84 [==============================] - 3s 40ms/step - loss: 0.4737 - accuracy: 0.2869 - val_loss: 0.6101 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.2857\n",
            "Train Loss     :  0.4902326464653015\n",
            "Train Accuracy :  28.574103116989136\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.6101 - accuracy: 0.0000e+00\n",
            "Test Loss      :  0.6101493239402771\n",
            "Test Accuracy  :  0.0\n",
            "Duration of execution : 20.09648323059082 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold"
      ],
      "metadata": {
        "id": "9OGqiENVdq18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((x_train, x_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "acc_per_fold, loss_per_fold = [], []\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "print(\"Start K-fold Cross Validation model evaluation:\", datetime.now())\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  ## Params\n",
        "  BATCH_SIZE = 32\n",
        "  EPOCH_COUNT = 10\n",
        "  FILE_NAME = \"train_kfolds5_cnngru_1\"\n",
        "\n",
        "  ## Main\n",
        "  model = MODEL()\n",
        "  history, model = model.training_model(x_train, y_train,x_test, y_test, len_data, depth_data, BATCH_SIZE, EPOCH_COUNT, FILE_NAME)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print(\"Finish K-fold Cross Validation model evaluation:\", datetime.now())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATTQJBMaEZCG",
        "outputId": "5448fa71-dab4-4645-8900-19ab252f01b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start K-fold Cross Validation model evaluation: 2022-06-28 11:04:18.162154\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Building model...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 203, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv_1 (Conv1D)                (None, 201, 64)      256         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 201, 64)     256         ['conv_1[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 100, 64)      0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 100, 64)      0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv_2 (Conv1D)                (None, 98, 198)      38214       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 98, 198)     792         ['conv_2[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 49, 198)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv_3 (Conv1D)                (None, 47, 384)      228480      ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 47, 384)     1536        ['conv_3[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 23, 384)     0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv_4 (Conv1D)                (None, 21, 384)      442752      ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 21, 384)     1536        ['conv_4[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 10, 384)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv_5 (Conv1D)                (None, 8, 198)       228294      ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 8, 198)      792         ['conv_5[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 4, 198)      0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 4, 198)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 792)          0           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 512)          397824      ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         812032      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 512)         2048        ['bidirectional[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          524800      ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 512)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          65664       ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 512)          0           ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " concat (Concatenate)           (None, 640)          0           ['dense_2[0][0]',                \n",
            "                                                                  'flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " preds (Dense)                  (None, 5)            3205        ['concat[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,748,481\n",
            "Trainable params: 2,745,001\n",
            "Non-trainable params: 3,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.9899\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99433, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 101s 41ms/step - loss: 0.3149 - accuracy: 0.9899 - val_loss: 0.1658 - val_accuracy: 0.9943 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9974\n",
            "Epoch 2: val_accuracy improved from 0.99433 to 0.99935, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 0.0951 - accuracy: 0.9974 - val_loss: 0.0627 - val_accuracy: 0.9993 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9991\n",
            "Epoch 3: val_accuracy improved from 0.99935 to 0.99972, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 0.0507 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9997 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9996\n",
            "Epoch 4: val_accuracy improved from 0.99972 to 0.99997, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 0.0153 - accuracy: 0.9996 - val_loss: 0.0075 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999\n",
            "Epoch 5: val_accuracy improved from 0.99997 to 1.00000, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 94s 40ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 1.6837e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.4969e-04 - accuracy: 0.9999\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 6.4969e-04 - accuracy: 0.9999 - val_loss: 3.6730e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 8.4068e-04 - accuracy: 0.9998\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 8.4068e-04 - accuracy: 0.9998 - val_loss: 1.8472e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 6.0947e-04 - accuracy: 0.9999\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 6.0939e-04 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9992 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 5.2935e-04 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 5.2915e-04 - accuracy: 1.0000 - val_loss: 5.2485e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 5.8524e-04 - accuracy: 0.9999\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 94s 40ms/step - loss: 5.8502e-04 - accuracy: 0.9999 - val_loss: 3.3482e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "2339/2339 [==============================] - 30s 13ms/step - loss: 5.3832e-06 - accuracy: 1.0000\n",
            "Train Loss     :  5.383204097597627e-06\n",
            "Train Accuracy :  100.0\n",
            "1003/1003 [==============================] - 13s 13ms/step - loss: 3.3482e-05 - accuracy: 1.0000\n",
            "Test Loss      :  3.3481832360848784e-05\n",
            "Test Accuracy  :  99.99688267707825\n",
            "Score for fold 1: loss of 3.3481832360848784e-05; accuracy of 99.99688267707825%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Building model...\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 203, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv_1 (Conv1D)                (None, 201, 64)      256         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 201, 64)     256         ['conv_1[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 100, 64)     0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100, 64)      0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv_2 (Conv1D)                (None, 98, 198)      38214       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 98, 198)     792         ['conv_2[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 49, 198)     0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv_3 (Conv1D)                (None, 47, 384)      228480      ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 47, 384)     1536        ['conv_3[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_7 (MaxPooling1D)  (None, 23, 384)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv_4 (Conv1D)                (None, 21, 384)      442752      ['max_pooling1d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 21, 384)     1536        ['conv_4[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d_8 (MaxPooling1D)  (None, 10, 384)     0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv_5 (Conv1D)                (None, 8, 198)       228294      ['max_pooling1d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 198)      792         ['conv_5[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_9 (MaxPooling1D)  (None, 4, 198)      0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 4, 198)       0           ['max_pooling1d_9[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 792)          0           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 512)         397824      ['input[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1024)         812032      ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 512)         2048        ['bidirectional_1[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 512)          524800      ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 512)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 128)          65664       ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 512)          0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " concat (Concatenate)           (None, 640)          0           ['dense_5[0][0]',                \n",
            "                                                                  'flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " preds (Dense)                  (None, 5)            3205        ['concat[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,748,481\n",
            "Trainable params: 2,745,001\n",
            "Non-trainable params: 3,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9905\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99542, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 94s 39ms/step - loss: 0.3056 - accuracy: 0.9905 - val_loss: 0.1791 - val_accuracy: 0.9954 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9973\n",
            "Epoch 2: val_accuracy improved from 0.99542 to 0.99707, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.1222 - accuracy: 0.9973 - val_loss: 0.0787 - val_accuracy: 0.9971 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9991\n",
            "Epoch 3: val_accuracy improved from 0.99707 to 0.99910, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0537 - accuracy: 0.9991 - val_loss: 0.2148 - val_accuracy: 0.9991 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9995\n",
            "Epoch 4: val_accuracy improved from 0.99910 to 0.99981, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0260 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9998\n",
            "Epoch 5: val_accuracy improved from 0.99981 to 0.99991, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 4.3085e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 5.6620e-04 - accuracy: 0.9999\n",
            "Epoch 6: val_accuracy improved from 0.99991 to 0.99997, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 5.6620e-04 - accuracy: 0.9999 - val_loss: 1.2444e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 7.2440e-04 - accuracy: 0.9999\n",
            "Epoch 7: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 7.2440e-04 - accuracy: 0.9999 - val_loss: 1.6410e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.8650e-04 - accuracy: 0.9998\n",
            "Epoch 8: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 6.8650e-04 - accuracy: 0.9998 - val_loss: 1.6546e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.1810e-04 - accuracy: 0.9999\n",
            "Epoch 9: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 6.1810e-04 - accuracy: 0.9999 - val_loss: 5.0565e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 5.3770e-04 - accuracy: 0.9999\n",
            "Epoch 10: val_accuracy improved from 0.99997 to 1.00000, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 5.3770e-04 - accuracy: 0.9999 - val_loss: 6.4540e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "2339/2339 [==============================] - 29s 12ms/step - loss: 4.6030e-06 - accuracy: 1.0000\n",
            "Train Loss     :  4.603038632922107e-06\n",
            "Train Accuracy :  100.0\n",
            "1003/1003 [==============================] - 13s 13ms/step - loss: 6.4540e-05 - accuracy: 1.0000\n",
            "Test Loss      :  6.45397522021085e-05\n",
            "Test Accuracy  :  100.0\n",
            "Score for fold 2: loss of 6.45397522021085e-05; accuracy of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Building model...\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 203, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv_1 (Conv1D)                (None, 201, 64)      256         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 201, 64)     256         ['conv_1[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_10 (MaxPooling1D  (None, 100, 64)     0           ['batch_normalization_12[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 100, 64)      0           ['max_pooling1d_10[0][0]']       \n",
            "                                                                                                  \n",
            " conv_2 (Conv1D)                (None, 98, 198)      38214       ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 98, 198)     792         ['conv_2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_11 (MaxPooling1D  (None, 49, 198)     0           ['batch_normalization_13[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_3 (Conv1D)                (None, 47, 384)      228480      ['max_pooling1d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 47, 384)     1536        ['conv_3[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_12 (MaxPooling1D  (None, 23, 384)     0           ['batch_normalization_14[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_4 (Conv1D)                (None, 21, 384)      442752      ['max_pooling1d_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 21, 384)     1536        ['conv_4[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_13 (MaxPooling1D  (None, 10, 384)     0           ['batch_normalization_15[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_5 (Conv1D)                (None, 8, 198)       228294      ['max_pooling1d_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 198)      792         ['conv_5[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_14 (MaxPooling1D  (None, 4, 198)      0           ['batch_normalization_16[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 4, 198)       0           ['max_pooling1d_14[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 792)          0           ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 512)         397824      ['input[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1024)         812032      ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 512)         2048        ['bidirectional_2[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 512)          524800      ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 512)          0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          65664       ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 512)          0           ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " concat (Concatenate)           (None, 640)          0           ['dense_8[0][0]',                \n",
            "                                                                  'flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            " preds (Dense)                  (None, 5)            3205        ['concat[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,748,481\n",
            "Trainable params: 2,745,001\n",
            "Non-trainable params: 3,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9908\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98507, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 94s 39ms/step - loss: 0.3011 - accuracy: 0.9908 - val_loss: 0.2814 - val_accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9976\n",
            "Epoch 2: val_accuracy improved from 0.98507 to 0.99246, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.1077 - accuracy: 0.9976 - val_loss: 0.1003 - val_accuracy: 0.9925 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9993\n",
            "Epoch 3: val_accuracy improved from 0.99246 to 0.99975, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0325 - accuracy: 0.9993 - val_loss: 0.0105 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9997\n",
            "Epoch 4: val_accuracy improved from 0.99975 to 0.99997, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0142 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
            "Epoch 5: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 90s 38ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 4.0065e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.7835e-04 - accuracy: 0.9998\n",
            "Epoch 6: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 6.7835e-04 - accuracy: 0.9998 - val_loss: 2.0702e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 5.5250e-04 - accuracy: 0.9999\n",
            "Epoch 7: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 5.5250e-04 - accuracy: 0.9999 - val_loss: 2.5486e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 4.4694e-04 - accuracy: 0.9999\n",
            "Epoch 8: val_accuracy did not improve from 0.99997\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 4.4694e-04 - accuracy: 0.9999 - val_loss: 9.1081e-05 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 8.4015e-04 - accuracy: 0.9998\n",
            "Epoch 9: val_accuracy improved from 0.99997 to 1.00000, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 8.4015e-04 - accuracy: 0.9998 - val_loss: 5.6244e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 3.4278e-04 - accuracy: 0.9999\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 90s 38ms/step - loss: 3.4278e-04 - accuracy: 0.9999 - val_loss: 2.4035e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "2339/2339 [==============================] - 30s 13ms/step - loss: 5.1907e-06 - accuracy: 1.0000\n",
            "Train Loss     :  5.190704086999176e-06\n",
            "Train Accuracy :  100.0\n",
            "1003/1003 [==============================] - 13s 13ms/step - loss: 2.4035e-05 - accuracy: 1.0000\n",
            "Test Loss      :  2.4035283786361106e-05\n",
            "Test Accuracy  :  100.0\n",
            "Score for fold 3: loss of 2.4035283786361106e-05; accuracy of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Building model...\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 203, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv_1 (Conv1D)                (None, 201, 64)      256         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 201, 64)     256         ['conv_1[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_15 (MaxPooling1D  (None, 100, 64)     0           ['batch_normalization_18[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 100, 64)      0           ['max_pooling1d_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv_2 (Conv1D)                (None, 98, 198)      38214       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 98, 198)     792         ['conv_2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_16 (MaxPooling1D  (None, 49, 198)     0           ['batch_normalization_19[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_3 (Conv1D)                (None, 47, 384)      228480      ['max_pooling1d_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 47, 384)     1536        ['conv_3[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_17 (MaxPooling1D  (None, 23, 384)     0           ['batch_normalization_20[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_4 (Conv1D)                (None, 21, 384)      442752      ['max_pooling1d_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 21, 384)     1536        ['conv_4[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_18 (MaxPooling1D  (None, 10, 384)     0           ['batch_normalization_21[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_5 (Conv1D)                (None, 8, 198)       228294      ['max_pooling1d_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 8, 198)      792         ['conv_5[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_19 (MaxPooling1D  (None, 4, 198)      0           ['batch_normalization_22[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 4, 198)       0           ['max_pooling1d_19[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 792)          0           ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 512)         397824      ['input[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1024)         812032      ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 512)         2048        ['bidirectional_3[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 512)          524800      ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 512)          0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 128)          65664       ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 512)          0           ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " concat (Concatenate)           (None, 640)          0           ['dense_11[0][0]',               \n",
            "                                                                  'flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " preds (Dense)                  (None, 5)            3205        ['concat[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,748,481\n",
            "Trainable params: 2,745,001\n",
            "Non-trainable params: 3,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.9904\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97088, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 99s 41ms/step - loss: 0.3274 - accuracy: 0.9904 - val_loss: 0.2460 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9970\n",
            "Epoch 2: val_accuracy improved from 0.97088 to 0.99829, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 97s 41ms/step - loss: 0.1036 - accuracy: 0.9970 - val_loss: 0.0438 - val_accuracy: 0.9983 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9987\n",
            "Epoch 3: val_accuracy improved from 0.99829 to 0.99913, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 96s 41ms/step - loss: 0.0549 - accuracy: 0.9987 - val_loss: 0.0353 - val_accuracy: 0.9991 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9995\n",
            "Epoch 4: val_accuracy improved from 0.99913 to 0.99966, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 0.0198 - accuracy: 0.9995 - val_loss: 0.0153 - val_accuracy: 0.9997 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9998\n",
            "Epoch 5: val_accuracy improved from 0.99966 to 0.99978, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 2.2708e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 6: val_accuracy improved from 0.99978 to 1.00000, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.5163e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 7.5045e-04 - accuracy: 0.9998\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 7.5018e-04 - accuracy: 0.9998 - val_loss: 6.7890e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 8.4029e-04 - accuracy: 0.9998\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 8.4029e-04 - accuracy: 0.9998 - val_loss: 7.2804e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 3.4972e-04 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 93s 40ms/step - loss: 3.4972e-04 - accuracy: 1.0000 - val_loss: 2.5699e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.2349e-04 - accuracy: 0.9999\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 6.2349e-04 - accuracy: 0.9999 - val_loss: 9.0052e-05 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "2339/2339 [==============================] - 30s 13ms/step - loss: 1.4056e-05 - accuracy: 1.0000\n",
            "Train Loss     :  1.4055513020139188e-05\n",
            "Train Accuracy :  100.0\n",
            "1003/1003 [==============================] - 13s 13ms/step - loss: 9.0052e-05 - accuracy: 0.9999\n",
            "Test Loss      :  9.005210449686274e-05\n",
            "Test Accuracy  :  99.9937653541565\n",
            "Score for fold 4: loss of 9.005210449686274e-05; accuracy of 99.9937653541565%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Building model...\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 203, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " conv_1 (Conv1D)                (None, 201, 64)      256         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 201, 64)     256         ['conv_1[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_20 (MaxPooling1D  (None, 100, 64)     0           ['batch_normalization_24[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 100, 64)      0           ['max_pooling1d_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv_2 (Conv1D)                (None, 98, 198)      38214       ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 98, 198)     792         ['conv_2[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_21 (MaxPooling1D  (None, 49, 198)     0           ['batch_normalization_25[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_3 (Conv1D)                (None, 47, 384)      228480      ['max_pooling1d_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 47, 384)     1536        ['conv_3[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_22 (MaxPooling1D  (None, 23, 384)     0           ['batch_normalization_26[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_4 (Conv1D)                (None, 21, 384)      442752      ['max_pooling1d_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 21, 384)     1536        ['conv_4[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_23 (MaxPooling1D  (None, 10, 384)     0           ['batch_normalization_27[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv_5 (Conv1D)                (None, 8, 198)       228294      ['max_pooling1d_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 8, 198)      792         ['conv_5[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling1d_24 (MaxPooling1D  (None, 4, 198)      0           ['batch_normalization_28[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 4, 198)       0           ['max_pooling1d_24[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 792)          0           ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 512)         397824      ['input[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 1024)         812032      ['flatten_8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 512)         2048        ['bidirectional_4[0][0]']        \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 512)          524800      ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 512)          0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          65664       ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 512)          0           ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " concat (Concatenate)           (None, 640)          0           ['dense_14[0][0]',               \n",
            "                                                                  'flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " preds (Dense)                  (None, 5)            3205        ['concat[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,748,481\n",
            "Trainable params: 2,745,001\n",
            "Non-trainable params: 3,480\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "2338/2339 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.9900\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99598, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 95s 39ms/step - loss: 0.3086 - accuracy: 0.9900 - val_loss: 0.1638 - val_accuracy: 0.9960 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy improved from 0.99598 to 0.99897, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 0.1072 - accuracy: 0.9972 - val_loss: 0.0425 - val_accuracy: 0.9990 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9995\n",
            "Epoch 3: val_accuracy improved from 0.99897 to 0.99991, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0480 - accuracy: 0.9995 - val_loss: 0.0185 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9997\n",
            "Epoch 4: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0199 - accuracy: 0.9997 - val_loss: 0.0683 - val_accuracy: 0.9991 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9998\n",
            "Epoch 5: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 0.0093 - accuracy: 0.9998 - val_loss: 4.0054e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 6.6090e-04 - accuracy: 0.9999\n",
            "Epoch 6: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 6.6090e-04 - accuracy: 0.9999 - val_loss: 3.4050e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 5.7693e-04 - accuracy: 0.9999\n",
            "Epoch 7: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 5.7693e-04 - accuracy: 0.9999 - val_loss: 2.0995e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 7.1276e-04 - accuracy: 0.9998\n",
            "Epoch 8: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 91s 39ms/step - loss: 7.1276e-04 - accuracy: 0.9998 - val_loss: 5.1243e-04 - val_accuracy: 0.9998 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 4.6851e-04 - accuracy: 0.9999\n",
            "Epoch 9: val_accuracy did not improve from 0.99991\n",
            "2339/2339 [==============================] - 92s 39ms/step - loss: 4.6851e-04 - accuracy: 0.9999 - val_loss: 1.7116e-04 - val_accuracy: 0.9999 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "2339/2339 [==============================] - ETA: 0s - loss: 7.3558e-04 - accuracy: 0.9998\n",
            "Epoch 10: val_accuracy improved from 0.99991 to 0.99997, saving model to ./models\\train_kfolds5_cnngru_1.h5\n",
            "2339/2339 [==============================] - 96s 41ms/step - loss: 7.3558e-04 - accuracy: 0.9998 - val_loss: 9.7554e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "\n",
            "Calculate loss and accuracy of the model\n",
            "\n",
            "2339/2339 [==============================] - 31s 13ms/step - loss: 3.6355e-05 - accuracy: 1.0000\n",
            "Train Loss     :  3.6355413612909615e-05\n",
            "Train Accuracy :  99.99866485595703\n",
            "1003/1003 [==============================] - 13s 13ms/step - loss: 9.7554e-05 - accuracy: 1.0000\n",
            "Test Loss      :  9.755354403750971e-05\n",
            "Test Accuracy  :  99.99688267707825\n",
            "Score for fold 5: loss of 9.755354403750971e-05; accuracy of 99.99688267707825%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 3.3481832360848784e-05 - Accuracy: 99.99688267707825%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 6.45397522021085e-05 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 2.4035283786361106e-05 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 9.005210449686274e-05 - Accuracy: 99.9937653541565%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 9.755354403750971e-05 - Accuracy: 99.99688267707825%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 99.9975061416626 (+- 0.002332790867427315)\n",
            "> Loss: 6.193250337673816e-05\n",
            "------------------------------------------------------------------------\n",
            "Finish K-fold Cross Validation model evaluation: 2022-06-28 12:25:57.467747\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_WtXp-dGPPjn",
        "nAHhcIPcXdj1",
        "82EXHh2B0l1F",
        "Ae4mrPzC8tz5",
        "8gSpgp6I9hVb",
        "s5HlHgGSTZlG",
        "9OGqiENVdq18"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}